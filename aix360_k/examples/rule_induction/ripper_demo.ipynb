{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aix360_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, accuracy_score, balanced_accuracy_score\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maix360_k\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maix360\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrule_induction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mripper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RipperExplainer\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aix360_k'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append('./')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score\n",
    "from aix360_k.aix360.algorithms.rule_induction.ripper import RipperExplainer\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Induction using RIPPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification with a random 20% test set\n",
    "\n",
    "We read the adult dataset from the UCI repository. The goal is to learn a rule describing people who earn more than 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = {'age': float,\n",
    "             'workclass': str,\n",
    "             'fnlwgt': float,\n",
    "             'education': str,\n",
    "             'education-num': float,\n",
    "             'marital-status': str,\n",
    "             'occupation': str,\n",
    "             'relationship': str,\n",
    "             'race': str,\n",
    "             'sex': str,\n",
    "             'capital-gain': float,\n",
    "             'capital-loss': float,\n",
    "             'native-country': str,\n",
    "             'hours-per-week': float,\n",
    "             'label': str}\n",
    "\n",
    "col_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "             'education-num', 'marital-status', 'occupation',\n",
    "             'relationship', 'race', 'sex',\n",
    "             'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "             'native-country', 'label']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
    "                 header=None,\n",
    "                 delimiter=', ',\n",
    "                 engine='python',\n",
    "                 names=col_names,\n",
    "                 dtype=data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comlum names shall not contain whitespace or arithmetic operators (+, -, *, /)\n",
    "We eventually output the rule set in TRXF format, where compound features are supported by parsing an expression string. So simple features like column names of a data frame must not contain these so that they are parsed as a single variable rather than an expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('-', '_')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'label'\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rule induction trains for specific 'foreground' aka 'positive' value of the target label, which we set to '>50K' below. This means that the rule set will characterize the set of adults who earn more than 50K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_VALUE = '>50K' # Setting positive value of the label for which we train\n",
    "values_dist = df[TARGET_COLUMN].value_counts()\n",
    "print('Positive value {} occurs {} times.'.format(POS_VALUE,values_dist[POS_VALUE]))\n",
    "print(values_dist)\n",
    "# This is distribution of the two values of the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# Split the data set into 80% training and 20% test set\n",
    "print('Training set:')\n",
    "print(train[TARGET_COLUMN].value_counts())\n",
    "print('Test set:')\n",
    "print(test[TARGET_COLUMN].value_counts())\n",
    "\n",
    "y_train = train[TARGET_COLUMN]\n",
    "x_train = train.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "y_test = test[TARGET_COLUMN]\n",
    "x_test = test.drop(columns=[TARGET_COLUMN])\n",
    "# Split data frames into features and label\n",
    "display(x_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Ripper estimator and train it using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RipperExplainer()\n",
    "\n",
    "start_time = time.time()\n",
    "estimator.fit(x_train, y_train, target_label=POS_VALUE) # Run RIPPER rule induction\n",
    "end_time = time.time()\n",
    "print('Training time (sec): ' + str(end_time - start_time))\n",
    "\n",
    "# compute performance metrics on test set\n",
    "y_pred = estimator.predict(x_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=POS_VALUE))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=POS_VALUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the rule set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trxf_ruleset = estimator.explain()\n",
    "print(str(trxf_ruleset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the resulting ruleset to a PMML file\n",
    "### Construct a RuleSetClassifier object\n",
    "A rule set by itself is merely a description of the given concept/target. Therefore, to use rule sets for a binary classification task, we must specify how to deal with potential overlaps between rule sets. For example, we could have learned 2 rule sets: one for >50K and another for <=50K. For instances where both rule sets are triggered, how do we classify that instance? There are 3 rule selection methods supported in PMML: First Hit, Weighted Sum, and Weighted Max. See here for more info: https://dmg.org/pmml/v4-4/RuleSet.html#xsdElement_RuleSelectionMethod. If we only learn a rule set for a single label, we can set a default label to which instances will be classified when the learned rule set does not trigger. \n",
    "\n",
    "In our case, since we only learn a rule set for a single label and use the default label for the rest, all 3 rule selection methods will have the same effect. However, if a rule selection method other than FirstHit is chosen, we need to compute the weights and confidence values for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aix360.algorithms.rule_induction.trxf.classifier.ruleset_classifier as trxf_classifier\n",
    "import aix360.algorithms.rule_induction.trxf.pmml_export as pmml\n",
    "classifier = trxf_classifier.RuleSetClassifier([trxf_ruleset],\n",
    "                                               rule_selection_method=trxf_classifier.RuleSelectionMethod.WEIGHTED_MAX,\n",
    "                                               confidence_metric=trxf_classifier.ConfidenceMetric.LAPLACE,\n",
    "                                               weight_metric=trxf_classifier.WeightMetric.CONFIDENCE,\n",
    "                                               default_label='1.0')\n",
    "classifier.update_rules_with_metrics(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the TRXF classifier to a PMML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pmml.TrxfReader()\n",
    "reader.load_data_dictionary(x_test)\n",
    "serializer = pmml.NyokaSerializer()\n",
    "exporter = pmml.PmmlExporter(reader, serializer)\n",
    "with open(\"adult_weighted_max.pmml\", \"w\") as text_file:\n",
    "    text_file.write(exporter.export(classifier))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
